<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Test-Time Training with Masked Autoencoders</title>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6">
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <style>
      body {
        font-family:Arial;
        font-size:20px;
        margin:60px auto;
        width:auto;
        max-width:900px;
      }

      hr {
        border:0;
        height:1.0px;
        background-image:linear-gradient(to right, rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.3));
      }

      .gap-30 {
      width:100%;
      height:30px;
      }

      .gap-20 {
      width:100%;
      height:20px;
      }

      .gap-10 {
      width:100%;
      height:10px;
      }

      .gap-5 {
      width:100%;
      height:5px;
      }
    </style>
  </head>

  <div class="container">
  <body>

    <center><span style="font-size:40px">
      Test-Time Training with Masked Autoencoders
    </span></center>
    <div class="gap-20"></div>

    <!---------------------  authors --------------------->
    <center>
    <span style="font-size:20px">
          &nbsp;
          <div style="display:inline-block">
          <a href="https://yossi.gandelsman.com">Yossi Gandelsman*</a>
          <sup style="font-size:15px">1</sup>,
          </div>
          &nbsp;
          <div style="display:inline-block">
          <a href="https://yueatsprograms.github.io">Yu Sun*</a>
          <sup style="font-size:15px">1</sup>,
          </div>
          &nbsp;
          <div style="display:inline-block">
          <a href="https://xinleic.xyz/">Xinlei Chen</a>
          <sup style="font-size:15px">2</sup>,
          </div>
          &nbsp;
          <div style="display:inline-block">
          <a href="https://people.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>
          <sup style="font-size:15px">1</sup>
          </div>
    </span>
	</center>
    <!--------------------- affiliations --------------------->
    <div class="gap-5"></div>
    <div class="row">
      <div class="col-md-3"></div>
      <div class="col-md-3">
        <center><span style="font-size:20px">
          UC Berkeley<sup style="font-size:15px">1</sup>
        </span></center>
      </div>
      <div class="col-md-3">
        <center><span style="font-size:20px">
          Meta AI<sup style="font-size:15px">2</sup>
        </span></center>
      </div>
      <div class="col-md-3"></div>
    </div>
    <p>* Equal contribution</p>
    <hr>

    <!--------------------- links --------------------->
    <div class="gap-10"></div>

    <center>
    <span style="font-size:20px"> 
      <b>NeurIPS 2022</b>
      &nbsp; 
      [<a href="">paper</a>]
      &nbsp;
      [<a href="">BibTeX</a>]
      &nbsp; 
      [<a href="https://github.com/yossigandelsman/test_time_training_mae">code (soon)</a>]
    </span>
    <div class="gap-20"></div>

    </center>
<img width="100%" src="images/teaser.png">
<p></p>
<p><i>We train an MAE to reconstruct each test image at test time, masking 75% of the input patches.
  The three reconstructed images on the right visualize the progress of this one-sample learning problem.
  Loss of the main task (green) - object recognition - keeps dropping even after 500 steps of gradient descent, while the network continues to optimize for reconstruction (red).
  </i></p>
<hr>
    <!--------------------- abstract --------------------->
    <div class="gap-20"></div>
    <b><span style="font-size:25px">Abstract</span></b><br>
    <div class="gap-10"></div>
    <p> 
    Test-time training adapts to a new test distribution on the fly by optimizing a model for each test input using self-supervision.
In this paper, we use masked autoencoders for this one-sample learning problem.
Empirically, our simple method improves generalization on many visual benchmarks for distribution shifts.
Theoretically, we characterize this improvement in terms of the bias-variance trade-off.
    </p>

    <hr>
    <!--------------------- content --------------------->
    <div class="gap-20"></div>
    <center><b><span style="font-size:25px">Paper</span></b>
    <br>
    <div class="gap-20"></div>
    <a href=""><img src="images/paper.png" style="border:1px solid #000000;" alt="" width="700"></a>
    </center>
    <!-- <table border="0">
    <tbody>
      <tr>
        <td></td>
        <td>&nbsp;</td>
        <td><p><br><a href="">"Test-Time Training with Masked Autoencoders"</a>,<br>Yossi Gandelsman*, Yu Sun*, Xinlei Chen and Alexei A. Efros.</p>
        </td>
      </tr>
    </tbody>
  </table> -->
  </body>
  </div>

  <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
  <!-- Include all compiled plugins (below), or include individual files as needed -->
  <script src="js/bootstrap.min.js"></script>

</html>